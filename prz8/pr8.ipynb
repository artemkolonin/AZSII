{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CEPlSbWq1N2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ffbb71-d0cd-433e-d29a-59a83a6ceca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0\n",
            "Epoch:1\n",
            "Epoch:2\n",
            "Epoch:3\n",
            "Epoch:4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Нормализация данных\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "# Преобразование меток в one-hot encoding\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "# Функция FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "  perturbation = epsilon * np.sign(gradient)\n",
        "  adversarial_image = image + perturbation\n",
        "  adversarial_image = np.clip(adversarial_image, 0, 1)\n",
        "  return adversarial_image\n",
        "# Функция для генерации противоречивых примеров\n",
        "def generate_adversarial_examples(model, images, labels, epsilon):\n",
        "  adversarial_images = []\n",
        "  for i in range(len(images)):\n",
        "    image = tf.convert_to_tensor(images[i].reshape((1, 28, 28)))\n",
        "    label = labels[i]\n",
        "    if len(label.shape) > 1 and label.shape[1] > 1:\n",
        "        label = np.argmax(label),\n",
        "    label = tf.convert_to_tensor(label)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(image)\n",
        "      prediction = model(image)\n",
        "      loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
        "    adversarial_images.append(adversarial_image.reshape(28, 28))\n",
        "  return np.array(adversarial_images)\n",
        "# Создание модели\n",
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "# Обучение модели с противоречивыми примерами\n",
        "def adversarial_training(model, train_images, train_labels, epsilon):\n",
        " for epoch in range(5): # Короткое обучение для демонстрации\n",
        "  print(f'Epoch:{epoch}')\n",
        "  for i in range(0, len(train_images), 64):\n",
        "    batch_images = train_images[i:i+64]\n",
        "    batch_labels = train_labels[i:i+64]\n",
        "    # Генерация противоречивых примеров для текущей партии данных\n",
        "    adversarial_images = generate_adversarial_examples(model, batch_images, batch_labels, epsilon)\n",
        "    # Объединение оригинальных и противоречивых примеров\n",
        "    combined_images = np.concatenate([batch_images, adversarial_images], axis=0)\n",
        "    combined_labels = np.concatenate([batch_labels, batch_labels], axis=0)\n",
        "    # Обучение на комбинированных данных\n",
        "    model.train_on_batch(combined_images, combined_labels)\n",
        "# Инициализация модели\n",
        "model = create_model()\n",
        "# Тренировка модели с защитой на противоречивых примерах\n",
        "adversarial_training(model, train_images[:1500], train_labels[:1500], epsilon=0.1) # ограничил тренировочные данные для ускорения обучения\n",
        "# Сохранение защищенной модели\n",
        "model.save('adversarial_trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OBoWZHwXfN1",
        "outputId": "fa368f8b-b6a6-4488-c183-c065f5916894"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.5702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4851238429546356, 0.8680999875068665]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Реализация градиентной маскировки\n",
        "# Для демонстрации мы можем использовать специальные функции активации\n",
        "from tensorflow.keras.layers import Activation\n",
        "# Обновление модели для градиентной маскировки\n",
        "def create_masked_model():\n",
        " model = tf.keras.Sequential([\n",
        " tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        " tf.keras.layers.Dense(128, activation='relu'),\n",
        " tf.keras.layers.Dense(10), Activation('softplus') # Используем softplus вместо softmax для градиентной маскировки\n",
        " ])\n",
        " model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " return model\n",
        "# Обучение модели с градиентной маскировкой\n",
        "masked_model = create_masked_model()\n",
        "masked_model.fit(train_images, train_labels, epochs=5)\n",
        "# Сохранение модели с градиентной маскировкой\n",
        "masked_model.save('masked_model.h5')"
      ],
      "metadata": {
        "id": "ugpMX05a2NQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dad34a-f8d9-47c9-bcd9-3fcc64099e5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 0.4679\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1214\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.0812\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0625\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель с регуляризацией и нормализацией\n",
        "def create_regularized_model():\n",
        " model = tf.keras.Sequential([\n",
        " tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        " tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        " tf.keras.layers.Dropout(0.5),\n",
        " tf.keras.layers.BatchNormalization(),\n",
        " tf.keras.layers.Dense(10, activation='softmax')\n",
        " ])\n",
        " model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        " return model\n",
        "# Обучение модели с регуляризацией и нормализацией\n",
        "regularized_model = create_regularized_model()\n",
        "regularized_model.fit(train_images, train_labels, epochs=5)\n",
        "# Сохранение модели с регуляризацией\n",
        "regularized_model.save('regularized_model.h5')"
      ],
      "metadata": {
        "id": "DIeTg0612Tm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d82efd-84cb-4c3b-90d1-06fdf1363d7a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 1.3433\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.6323\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.6335\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.6234\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.6126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка атакованной модели\n",
        "protected_model = tf.keras.models.load_model('adversarial_trained_model.h5')\n",
        "# Генерация противоречивых примеров для тестовых данных\n",
        "adversarial_test_images = generate_adversarial_examples(protected_model, test_images[1000:2000], test_labels[1000:2000], epsilon=0.1)\n",
        "# Оценка защищенной модели на противоречивых примерах\n",
        "test_loss, test_acc = protected_model.evaluate(adversarial_test_images, test_labels[1000:2000])\n",
        "print(f'Accuracy of protected model on adversarial examples: {test_acc}')"
      ],
      "metadata": {
        "id": "l2GC4VuT2aIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a6409b-3be5-4967-ee43-51abfd94e10e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.4243 - loss: 1.6112\n",
            "Accuracy of protected model on adversarial examples: 0.4440000057220459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель, обученная на противоречивых примерах, показала плохой результат на незнакомых данных. Противоречивые примеры создавались конкретно для данной модели.\n",
        "\n",
        "Проверим также её точность на атакованных данных, используемых при обучении"
      ],
      "metadata": {
        "id": "b6W0fnc6Y2vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_test_images = generate_adversarial_examples(protected_model, train_images[:1000], train_labels[:1000], epsilon=0.1)\n",
        "# Оценка защищенной модели на противоречивых примерах\n",
        "test_loss, test_acc = protected_model.evaluate(adversarial_test_images, train_labels[:1000])\n",
        "print(f'Accuracy of protected model on adversarial examples: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WAhtp5zYUNS",
        "outputId": "d6482934-c3dd-465a-d268-67489bd4d626"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 1.0497 \n",
            "Accuracy of protected model on adversarial examples: 0.6610000133514404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не самая выдающаяся точность. Возможно, можно её повысить, увеличив время обучения и выборку, что, однако, очень требовательно к вычислительным ресурсам"
      ],
      "metadata": {
        "id": "mx_Nkb-KZB33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = create_model()\n",
        "base_model.fit(train_images, train_labels, epochs=5)\n",
        "# --- Оценка моделей на противоречивых примерах ---\n",
        "test_adversarial_images = generate_adversarial_examples(base_model, test_images[:3000], test_labels[:3000], epsilon=0.1)"
      ],
      "metadata": {
        "id": "JnCSuV_X2euX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0117e78f-0f89-4c97-ff05-15a89d1bb730"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.4271\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9641 - loss: 0.1232\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0783\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0553\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка защищенных моделей\n",
        "print(\"Evaluation of models on adversarial examples:\")\n",
        "print(\"Base Model Accuracy on Adversarial Examples:\")\n",
        "base_model.evaluate(test_adversarial_images, test_labels[:3000])\n",
        "print(\"Adversarially Trained Model Accuracy on Adversarial Examples:\")\n",
        "protected_model.evaluate(test_adversarial_images, test_labels[:3000])\n",
        "print(\"Masked Model Accuracy on Adversarial Examples:\")\n",
        "masked_model.evaluate(test_adversarial_images, test_labels[:3000])\n",
        "print(\"Regularized Model Accuracy on Adversarial Examples:\")\n",
        "regularized_model.evaluate(test_adversarial_images, test_labels[:3000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvWDPGFsam1F",
        "outputId": "1a594196-f5e6-4b71-d979-2debdf7615f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation of models on adversarial examples:\n",
            "Base Model Accuracy on Adversarial Examples:\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1022 - loss: 6.6053\n",
            "Adversarially Trained Model Accuracy on Adversarial Examples:\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6924 - loss: 0.9503\n",
            "Masked Model Accuracy on Adversarial Examples:\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2210 - loss: 4.6751\n",
            "Regularized Model Accuracy on Adversarial Examples:\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6766 - loss: 1.1007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1625213623046875, 0.6543333530426025]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, модель, обученная на противоречивых примерах, и модель с регуляризацией и нормализацией показали неплохой результат. А модель с маскировкой спраивлась гораздо хуже. Конечно, каждая из моделей справилась лучше, чем модель без защиты, но точность ~65% вряд ли можно назвать удовлетворительной. Впрочем, каждое из изображений в данном тесте было противоречивым, так что можно утверждать, что как минимум половина атак FGSM не повлияют на модели с противоречивым обучением и регуляризацией с нормализацией"
      ],
      "metadata": {
        "id": "J843Dw2AbHiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Противоречивые примеры были сгенерированы на базовой модели. Посмотрим, как поведут себя модели, если противоречивые примеры будут сгенерированы конкретно для них (вариант для обученной на противоречивых данных модели был показан выше, поэтому будет пропущен)"
      ],
      "metadata": {
        "id": "tlWCNlBxb8Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_test_images = generate_adversarial_examples(masked_model, train_images[:1000], train_labels[:1000], epsilon=0.1)\n",
        "# Оценка защищенной модели на противоречивых примерах\n",
        "test_loss, test_acc = masked_model.evaluate(adversarial_test_images, train_labels[:1000])\n",
        "print(f'Accuracy of masked model on adversarial examples: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZrRSux_aPjZ",
        "outputId": "90e74a1a-8f8c-41d7-d600-664858724f67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1349 - loss: 6.1444\n",
            "Accuracy of masked model on adversarial examples: 0.14499999582767487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_test_images = generate_adversarial_examples(regularized_model, train_images[:1000], train_labels[:1000], epsilon=0.1)\n",
        "# Оценка защищенной модели на противоречивых примерах\n",
        "test_loss, test_acc = regularized_model.evaluate(adversarial_test_images, train_labels[:1000])\n",
        "print(f'Accuracy of regularized model on adversarial examples: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an27RH3Mce11",
        "outputId": "0f19a703-b4cb-4e5c-fef2-cfeae574dcb9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4902 - loss: 1.6612\n",
            "Accuracy of regularized model on adversarial examples: 0.460999995470047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из данных тестов видно, что при атаке на конкретную модель точность упадёт ещё сильнее, а маскированная модель справляется совсем плохо. Таким образом, наиболее успешными себя показали модель, обученная на противоречивых примерах, и модель с регуляризацией и нормализацией"
      ],
      "metadata": {
        "id": "WABDN9MFdAni"
      }
    }
  ]
}